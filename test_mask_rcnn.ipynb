{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d556b42-466d-4e7a-8868-5e4556e8d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision scikit-learn matplotlib seaborn tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eee75dc-651a-435c-ace3-80e78b5f863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models.detection import MaskRCNN\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "from torchvision.transforms import v2 as T\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import draw_bounding_boxes, draw_segmentation_masks\n",
    "from torchvision.ops import nms, box_iou\n",
    "import torchvision.ops as ops\n",
    "from torchvision.models.detection.anchor_utils import AnchorGenerator\n",
    "from torchvision.ops import MultiScaleRoIAlign\n",
    "from torchvision.ops.boxes import masks_to_boxes\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.transforms.functional import InterpolationMode, resize\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from torch.nn import functional as F\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69607478-2640-470b-9bc1-fcc4c93729b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3e9eef-7c9e-476c-bd60-dd72f400f079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms.v2 as T\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transforms=None, iou_threshold=0.5, min_area=100):\n",
    "        self.root_dir = root_dir\n",
    "        self.transforms = transforms\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.min_area = min_area\n",
    "\n",
    "        self.imgs = []\n",
    "        self.masks = []\n",
    "        self.manu_to_label = {}\n",
    "        label_counter = 1\n",
    "\n",
    "        for manu_name in os.listdir(root_dir):\n",
    "            manu_path = os.path.join(root_dir, manu_name)\n",
    "            if not os.path.isdir(manu_path) or manu_name.startswith('.'):\n",
    "                continue\n",
    "\n",
    "            if manu_name.lower() in [\"no manufacturer data\", \"no accession number match\", \"rti\"]:\n",
    "                continue\n",
    "\n",
    "            if manu_name not in self.manu_to_label:\n",
    "                self.manu_to_label[manu_name] = label_counter\n",
    "                label_counter += 1\n",
    "\n",
    "            for ind_name in os.listdir(manu_path):\n",
    "                ind_path = os.path.join(manu_path, ind_name)\n",
    "                if not os.path.isdir(ind_path) or ind_name.startswith('.'):\n",
    "                    continue\n",
    "\n",
    "                images_path = os.path.join(ind_path, \"images\")\n",
    "                masks_path = os.path.join(ind_path, \"masks\")\n",
    "\n",
    "                if os.path.exists(images_path) and os.path.exists(masks_path):\n",
    "                    for img_name in os.listdir(images_path):\n",
    "                        if not img_name.startswith('.'):\n",
    "                            img_path = os.path.join(images_path, img_name)\n",
    "                            mask_base = os.path.splitext(img_name)[0]\n",
    "                            mask_name = f\"{mask_base}_mask.jpg\"\n",
    "                            mask_path = os.path.join(masks_path, mask_name)\n",
    "                            if os.path.exists(mask_path):\n",
    "                                self.imgs.append((img_path, manu_name))\n",
    "                                self.masks.append(mask_path)\n",
    "\n",
    "        print(f\"Found {len(self.imgs)} images and {len(self.masks)} masks\")\n",
    "        print(\"Manufacturer to label mapping:\", self.manu_to_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def _process_mask(self, mask):\n",
    "\n",
    "\n",
    "        unique_mask = mask[0, :, :] + mask[1, :, :] * 256 + mask[2, :, :] * 256 * 256\n",
    "        binary_mask = (unique_mask > 0)\n",
    "        binary_np = binary_mask.numpy()\n",
    "        filled_binary = ndimage.binary_fill_holes(binary_np)\n",
    "        cross = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]], dtype=np.bool_)\n",
    "        closed = ndimage.binary_closing(filled_binary, structure=cross, iterations=1)\n",
    "        final_filled = ndimage.binary_fill_holes(closed)\n",
    "        labeled_array, num_features = ndimage.label(final_filled)\n",
    "        labeled_mask = torch.from_numpy(labeled_array)\n",
    "\n",
    "        masks = []\n",
    "        for i in range(1, num_features + 1):\n",
    "            component_mask = (labeled_mask == i)\n",
    "            if torch.sum(component_mask) > self.min_area:\n",
    "                masks.append(component_mask)\n",
    "\n",
    "        return torch.stack(masks) if masks else torch.zeros((0, mask.shape[1], mask.shape[2]), dtype=torch.bool)\n",
    "\n",
    "    def _get_tight_boxes(self, masks, base_padding=5):\n",
    "        boxes = []\n",
    "        filtered_masks = []\n",
    "\n",
    "        for mask in masks:\n",
    "            y_indices, x_indices = torch.where(mask)\n",
    "            if len(y_indices) > 0 and len(x_indices) > 0:\n",
    "                x_min_raw = torch.min(x_indices).item()\n",
    "                y_min_raw = torch.min(y_indices).item()\n",
    "                x_max_raw = torch.max(x_indices).item()\n",
    "                y_max_raw = torch.max(y_indices).item()\n",
    "\n",
    "                raw_width = x_max_raw - x_min_raw\n",
    "                raw_height = y_max_raw - y_min_raw\n",
    "                mask_area = torch.sum(mask).item()\n",
    "                area_factor = min(1.5, max(1.0, (mask_area / 10000) * 1.2))\n",
    "\n",
    "                if raw_width > raw_height * 2:\n",
    "                    padding = base_padding * 1.4 * area_factor\n",
    "                elif raw_height > raw_width * 2:\n",
    "                    padding = base_padding * 1.4 * area_factor\n",
    "                else:\n",
    "                    padding = base_padding * area_factor\n",
    "\n",
    "                x_min = max(0, x_min_raw - padding)\n",
    "                y_min = max(0, y_min_raw - padding)\n",
    "                x_max = min(mask.shape[1], x_max_raw + padding)\n",
    "                y_max = min(mask.shape[0], y_max_raw + padding)\n",
    "\n",
    "                width = x_max - x_min\n",
    "                height = y_max - y_min\n",
    "                area = width * height\n",
    "                aspect_ratio = width / height if height > 0 else 0\n",
    "\n",
    "                if area > self.min_area * 0.8 and 0.1 < aspect_ratio < 10:\n",
    "                    boxes.append([x_min, y_min, x_max, y_max])\n",
    "                    filtered_masks.append(mask)\n",
    "\n",
    "        return (torch.tensor(boxes, dtype=torch.float32) if boxes else torch.zeros((0, 4), dtype=torch.float32)), filtered_masks\n",
    "\n",
    "    def _apply_nms(self, boxes, scores=None, iou_threshold=None):\n",
    "        if len(boxes) == 0:\n",
    "            return torch.tensor([], dtype=torch.int64)\n",
    "        if scores is None:\n",
    "            scores = torch.ones(len(boxes))\n",
    "        threshold = self.iou_threshold if iou_threshold is None else iou_threshold\n",
    "        from torchvision.ops import nms\n",
    "        return nms(boxes, scores, threshold)\n",
    "\n",
    "    def _resize_with_lockstep_precision(self, img, mask, target_size=2048):\n",
    "\n",
    "        c_img, h, w = img.shape\n",
    "        c_mask = mask.shape[0]\n",
    "        scale = min(target_size / h, target_size / w)\n",
    "        new_h, new_w = int(h * scale), int(w * scale)\n",
    "\n",
    "        resized_img = resize(img, size=(new_h, new_w), interpolation=InterpolationMode.BILINEAR, antialias=True)\n",
    "        resized_mask = resize(mask, size=(new_h, new_w), interpolation=InterpolationMode.NEAREST)\n",
    "\n",
    "        padded_img = torch.zeros((c_img, target_size, target_size), dtype=img.dtype)\n",
    "        padded_mask = torch.zeros((c_mask, target_size, target_size), dtype=mask.dtype)\n",
    "\n",
    "        h_offset = (target_size - new_h) // 2\n",
    "        w_offset = (target_size - new_w) // 2\n",
    "\n",
    "        padded_img[:, h_offset:h_offset+new_h, w_offset:w_offset+new_w] = resized_img\n",
    "        padded_mask[:, h_offset:h_offset+new_h, w_offset:w_offset+new_w] = resized_mask\n",
    "\n",
    "        return padded_img, padded_mask, (h_offset, w_offset, new_h, new_w)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, manu = self.imgs[idx]\n",
    "        mask_path = self.masks[idx]\n",
    "\n",
    "        img = read_image(img_path)\n",
    "        if img.shape[0] == 1:\n",
    "            img = img.repeat(3, 1, 1)\n",
    "        img = img.float() / 255.0 if img.max() > 1.0 else img.float()\n",
    "\n",
    "        mask = read_image(mask_path).byte()\n",
    "        img, mask, _ = self._resize_with_lockstep_precision(img, mask, 2048)\n",
    "\n",
    "        masks = self._process_mask(mask)\n",
    "        boxes, filtered_masks = self._get_tight_boxes(masks, base_padding=2)\n",
    "\n",
    "        if len(boxes) > 0:\n",
    "            keep = self._apply_nms(boxes)\n",
    "            boxes = boxes[keep]\n",
    "            filtered_masks = [filtered_masks[i] for i in keep] if filtered_masks else []\n",
    "            masks = torch.stack(filtered_masks) if filtered_masks else torch.zeros((0, mask.shape[1], mask.shape[2]), dtype=torch.bool)\n",
    "        else:\n",
    "            masks = torch.zeros((0, mask.shape[1], mask.shape[2]), dtype=torch.bool)\n",
    "\n",
    "        labels = torch.full((boxes.shape[0],), self.manu_to_label[manu], dtype=torch.int64)\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"masks\": masks,\n",
    "            \"area\": area,\n",
    "            \"image_id\": torch.tensor([idx]),\n",
    "            \"iscrowd\": torch.zeros((boxes.shape[0],), dtype=torch.int64)\n",
    "        }\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        h, w = img.shape[1:]\n",
    "        boxes = target[\"boxes\"]\n",
    "        boxes[:, 0].clamp_(0, w - 1)\n",
    "        boxes[:, 1].clamp_(0, h - 1)\n",
    "        boxes[:, 2].clamp_(0, w - 1)\n",
    "        boxes[:, 3].clamp_(0, h - 1)\n",
    "        target[\"boxes\"] = boxes\n",
    "\n",
    "        return img, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c51197-1c43-4112-a7a9-ad8fa146e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train=False):\n",
    "    return T.Compose([\n",
    "        T.ToImage(),  # Converts to C x H x W tensor\n",
    "        T.ToDtype(torch.float, scale=True)  # Converts to float in [0,1]\n",
    "    ])\n",
    "\n",
    "def load_model(num_classes, device):\n",
    "    sizes = ((32,), (64,), (128,), (256,), (512,))\n",
    "    aspect_ratios = ((0.2, 0.3, 0.5, 1.0, 2.0, 3.0),) * len(sizes)\n",
    "    anchor_generator = AnchorGenerator(sizes=sizes, aspect_ratios=aspect_ratios)\n",
    "    roi_pooler = MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=7, sampling_ratio=2)\n",
    "\n",
    "    backbone = resnet_fpn_backbone(\"resnet18\", weights=\"DEFAULT\")\n",
    "    model = MaskRCNN(\n",
    "        backbone, num_classes=num_classes,\n",
    "        rpn_anchor_generator=anchor_generator,\n",
    "        box_roi_pool=roi_pooler,\n",
    "        rpn_score_thresh=0.3,\n",
    "        box_score_thresh=0.3,\n",
    "        box_nms_thresh=0.25\n",
    "    )\n",
    "    model.rpn.post_nms_top_n_train = 200\n",
    "    model.rpn.post_nms_top_n_test = 110 \n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387da60d-0eb5-4681-8686-6ef851ad3063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(image_tensor, prediction, ground_truth=None, label_map=None, score_thresh=0.3, iou_thresh=0.3):\n",
    "    \"\"\"\n",
    "    Displays an image with predicted masks, boxes, and labels.\n",
    "    Matches GT and predicted boxes using IoU, and annotates accordingly.\n",
    "\n",
    "    Args:\n",
    "        image_tensor (Tensor): The input image tensor (C, H, W).\n",
    "        prediction (Dict): Model predictions with keys: boxes, labels, scores, (optional) masks.\n",
    "        ground_truth (Dict, optional): Ground truth boxes and labels.\n",
    "        label_map (Dict[int, str], optional): Mapping of class indices to names.\n",
    "        score_thresh (float): Score threshold for filtering predictions.\n",
    "        iou_thresh (float): IoU threshold for matching GT and predictions.\n",
    "    \"\"\"\n",
    "    # Prepare image\n",
    "    image = (image_tensor.clone() * 255).byte()\n",
    "    if image.ndim == 3 and image.shape[0] == 1:\n",
    "        image = image.expand(3, -1, -1)\n",
    "\n",
    "    # Extract and filter predictions\n",
    "    boxes_pred = prediction['boxes']\n",
    "    labels_pred = prediction['labels']\n",
    "    scores_pred = prediction['scores']\n",
    "    masks_pred = prediction.get('masks')\n",
    "\n",
    "    keep = scores_pred > score_thresh\n",
    "    boxes_pred = boxes_pred[keep]\n",
    "    labels_pred = labels_pred[keep]\n",
    "    scores_pred = scores_pred[keep]\n",
    "    if masks_pred is not None and len(masks_pred) > 0:\n",
    "        masks_pred = masks_pred[keep].squeeze(1) > 0.5\n",
    "\n",
    "    # Initialize labels for all predicted boxes\n",
    "    label_texts = [\n",
    "        f\"Pred: {label_map.get(l.item(), l.item())} ({s.item():.2f})\" if label_map else f\"Pred: {l.item()} ({s.item():.2f})\"\n",
    "        for l, s in zip(labels_pred, scores_pred)\n",
    "    ]\n",
    "\n",
    "    # Match predictions to ground truth and update label text if matched\n",
    "    if ground_truth and len(boxes_pred) > 0 and len(ground_truth['boxes']) > 0:\n",
    "        boxes_gt = ground_truth['boxes']\n",
    "        labels_gt = ground_truth['labels']\n",
    "        ious = box_iou(boxes_gt, boxes_pred)\n",
    "\n",
    "        for gt_idx, gt_label in enumerate(labels_gt):\n",
    "            iou_row = ious[gt_idx]\n",
    "            max_iou, pred_idx = iou_row.max(0)\n",
    "            if max_iou > iou_thresh:\n",
    "                pred_idx = pred_idx.item()\n",
    "                gt_text = label_map.get(gt_label.item(), gt_label.item()) if label_map else str(gt_label.item())\n",
    "                pred_text = label_map.get(labels_pred[pred_idx].item(), labels_pred[pred_idx].item()) if label_map else str(labels_pred[pred_idx].item())\n",
    "                score = scores_pred[pred_idx].item()\n",
    "                label_texts[pred_idx] = f\"GT: {gt_text} | Pred: {pred_text} ({score:.2f})\"\n",
    "\n",
    "    # Draw boxes and labels\n",
    "    image_with_boxes = draw_bounding_boxes(image, boxes_pred, labels=label_texts, width=2)\n",
    "\n",
    "    # Draw masks if present\n",
    "    if masks_pred is not None and len(masks_pred) > 0:\n",
    "        image_with_boxes = draw_segmentation_masks(image_with_boxes, masks=masks_pred, alpha=0.3)\n",
    "\n",
    "    # Show image\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image_with_boxes.permute(1, 2, 0))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"GT vs Predicted Labels\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b62a8f-21ec-433a-86c7-c30fdf7a2281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard visualization function\n",
    "def visualize_tb(writer, image, output, sample_idx, prefix=\"prediction\", label_map=None):\n",
    "    \"\"\"\n",
    "    Visualize the model's predictions by drawing bounding boxes and masks on the image.\n",
    "    Args:\n",
    "        writer (SummaryWriter): TensorBoard SummaryWriter to log the image.\n",
    "        image (Tensor): The input image tensor.\n",
    "        output (Dict): The model's output containing boxes, scores, labels, and masks.\n",
    "        sample_idx (int): The sample index for unique identification.\n",
    "        prefix (str): Prefix for the TensorBoard tag.\n",
    "        label_map (Dict): Label mapping for manufacturer names.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Normalize the image to the range [0, 255] and convert to uint8\n",
    "        if image.dtype != torch.uint8:\n",
    "            image = (255.0 * (image - image.min()) / (image.max() - image.min())).to(torch.uint8)\n",
    "        image = image[:3, ...]  # Ensure the image has 3 channels\n",
    "        \n",
    "        if \"boxes\" in output and len(output[\"boxes\"]) > 0:\n",
    "            # Apply Non-Maximum Suppression (NMS) to filter boxes\n",
    "            keep = nms(output[\"boxes\"], output[\"scores\"], iou_threshold=0.3)\n",
    "            \n",
    "            # Create labels for the predicted boxes\n",
    "            if label_map:\n",
    "                pred_labels = [f\"{label_map.get(label.item(), f'manu: {label.item()}')}|{score:.3f}%\"\n",
    "                               for label, score in zip(output[\"labels\"][keep], output[\"scores\"][keep])]\n",
    "            else:\n",
    "                pred_labels = [f\"manu: {label}|{score:.3f}%\"\n",
    "                               for label, score in zip(output[\"labels\"][keep], output[\"scores\"][keep])]\n",
    "            \n",
    "            # Get the filtered boxes\n",
    "            pred_boxes = output[\"boxes\"][keep].long()\n",
    "            # Draw the bounding boxes on the image\n",
    "            output_image = draw_bounding_boxes(image, pred_boxes, pred_labels, colors=\"red\")\n",
    "            \n",
    "            if \"masks\" in output and len(output[\"masks\"]) > 0:\n",
    "                # Get the filtered masks\n",
    "                masks = (output[\"masks\"][keep] > 0.7).squeeze(1)\n",
    "                # Draw the segmentation masks on the image\n",
    "                output_image = draw_segmentation_masks(output_image, masks, alpha=0.5, colors=\"blue\")\n",
    "        else:\n",
    "            output_image = image\n",
    "            \n",
    "        # Log the image with bounding boxes and masks to TensorBoard\n",
    "        writer.add_image(f\"{prefix}_From_Sample_{sample_idx}\", output_image, sample_idx)\n",
    "    except Exception as e:\n",
    "        print(f\"Visualization error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb62f0d1-72fb-453e-afa8-344e5cb47194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device, dataset, iou_threshold=0.3, visualize_samples=10):\n",
    "    \"\"\"\n",
    "    Evaluate model and visualize predictions for all images.\n",
    "    \"\"\"\n",
    "    # Add TensorBoard writer initialization\n",
    "    writer = SummaryWriter('runs/mask_rcnn_evaluation_latest_v1')\n",
    "    \n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    label_map = dataset.dataset.manu_to_label\n",
    "    inv_label_map = {v: k for k, v in label_map.items()}\n",
    "    \n",
    "    # Add counter for TensorBoard\n",
    "    tb_sample_counter = 0\n",
    "    batch_counter = 0\n",
    "    running_correct = 0\n",
    "    running_total = 0\n",
    "    \n",
    "    # For saving sample images\n",
    "    sample_counter = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(dataloader, desc=\"Evaluating and Visualizing\"):\n",
    "            images = [img.to(device) for img in images]\n",
    "            predictions = model(images)\n",
    "\n",
    "            for image, pred, gt in zip(images, predictions, targets):\n",
    "                gt_boxes = gt['boxes'].cpu()\n",
    "                gt_labels = gt['labels'].cpu().tolist()\n",
    "\n",
    "                pred_boxes = pred['boxes'].cpu()\n",
    "                pred_scores = pred['scores'].cpu()\n",
    "                pred_labels = pred['labels'].cpu()\n",
    "                pred_masks = pred['masks'].cpu().squeeze(1) if 'masks' in pred else None\n",
    "\n",
    "                # Simple threshold - no adaptive correction\n",
    "                keep = pred_scores > 0.3\n",
    "                pred_boxes = pred_boxes[keep]\n",
    "                pred_labels = pred_labels[keep]\n",
    "                pred_scores = pred_scores[keep]\n",
    "                pred_masks = pred_masks[keep] if pred_masks is not None else None\n",
    "\n",
    "                if len(pred_boxes) == 0:\n",
    "                    y_true.extend(gt_labels)\n",
    "                    y_pred.extend([0] * len(gt_labels))\n",
    "                else:\n",
    "                    ious = box_iou(gt_boxes, pred_boxes)\n",
    "                    for i, gt_label in enumerate(gt_labels):\n",
    "                        iou_row = ious[i]\n",
    "                        max_iou, max_idx = iou_row.max(0)\n",
    "                        if max_iou > iou_threshold:\n",
    "                            matched_label = pred_labels[max_idx].item()\n",
    "                            y_true.append(gt_label)\n",
    "                            y_pred.append(matched_label)\n",
    "                        else:\n",
    "                            y_true.append(gt_label)\n",
    "                            y_pred.append(0)\n",
    "\n",
    "                # Update running accuracy\n",
    "                batch_pred = y_pred[-len(gt_labels):]\n",
    "                batch_true = y_true[-len(gt_labels):]\n",
    "                running_correct += sum([t == p for t, p in zip(batch_true, batch_pred)])\n",
    "                running_total += len(batch_true)\n",
    "                \n",
    "                # Log running accuracy every 10 batches\n",
    "                if batch_counter % 10 == 0 and running_total > 0:\n",
    "                    current_acc = 100.0 * running_correct / running_total\n",
    "                    writer.add_scalar('Accuracy/per_screw_running', current_acc, batch_counter)\n",
    "                \n",
    "                batch_counter += 1\n",
    "\n",
    "                # Add TensorBoard visualization for detections\n",
    "                if tb_sample_counter < 50:\n",
    "                    pred_for_tb = {\n",
    "                        'boxes': pred_boxes,\n",
    "                        'labels': pred_labels,\n",
    "                        'scores': pred_scores,\n",
    "                        'masks': pred_masks\n",
    "                    }\n",
    "                    visualize_tb(writer, image.cpu(), pred_for_tb, tb_sample_counter, \n",
    "                               \"predictions\", inv_label_map)\n",
    "                    tb_sample_counter += 1\n",
    "\n",
    "                if sample_counter < visualize_samples:\n",
    "                    img_cpu = image.cpu()\n",
    "                    \n",
    "                    # Convert image to proper format for visualization\n",
    "                    if img_cpu.dtype != torch.uint8:\n",
    "                        img_cpu = (img_cpu * 255).byte()\n",
    "                    \n",
    "                    # Create figure\n",
    "                    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
    "                    \n",
    "                    # Ground truth visualization\n",
    "                    gt_img = img_cpu.clone()\n",
    "                    if len(gt_boxes) > 0:\n",
    "                        gt_labels_text = [f\"{inv_label_map.get(label, f'Class {label}')}\" \n",
    "                                         for label in gt_labels]\n",
    "                        gt_img = draw_bounding_boxes(gt_img, gt_boxes, \n",
    "                                                    labels=gt_labels_text, \n",
    "                                                    colors=\"green\", width=2)\n",
    "                    \n",
    "                    ax1.imshow(gt_img.permute(1, 2, 0))\n",
    "                    ax1.set_title(\"Ground Truth\")\n",
    "                    ax1.axis('off')\n",
    "                    \n",
    "                    # Predictions visualization\n",
    "                    pred_img = img_cpu.clone()\n",
    "                    if len(pred_boxes) > 0:\n",
    "                        pred_labels_text = [f\"{inv_label_map.get(label.item(), f'Class {label.item()}')} ({score:.2f})\" \n",
    "                                           for label, score in zip(pred_labels, pred_scores)]\n",
    "                        pred_img = draw_bounding_boxes(pred_img, pred_boxes, \n",
    "                                                      labels=pred_labels_text, \n",
    "                                                      colors=\"red\", width=2)\n",
    "                        \n",
    "                        if pred_masks is not None and len(pred_masks) > 0:\n",
    "                            pred_img = draw_segmentation_masks(pred_img, \n",
    "                                                             masks=pred_masks > 0.5, \n",
    "                                                             alpha=0.4)\n",
    "                    \n",
    "                    ax2.imshow(pred_img.permute(1, 2, 0))\n",
    "                    ax2.set_title(\"Predictions\")\n",
    "                    ax2.axis('off')\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "\n",
    "                    writer.add_figure(f'Sample_Images/sample_{sample_counter}', fig, global_step=0)\n",
    "                    \n",
    "                    plt.savefig(f'sample_evaluation_{sample_counter}.png', \n",
    "                               bbox_inches='tight', dpi=150)\n",
    "                    plt.close(fig)\n",
    "                    \n",
    "                    sample_counter += 1\n",
    "\n",
    "    print(\"\\n--- Per-Screw Classification Report ---\")\n",
    "    \n",
    "    report_dict = classification_report(y_true, y_pred, labels=list(range(1, 7)), \n",
    "                                       zero_division=0, output_dict=True)\n",
    "    print(classification_report(y_true, y_pred, labels=list(range(1, 7)), zero_division=0))\n",
    "    \n",
    "    # Log per-class metrics to TensorBoard\n",
    "    for label in range(1, 7):\n",
    "        label_name = inv_label_map.get(label, f\"Class_{label}\")\n",
    "        if str(label) in report_dict:\n",
    "            writer.add_scalar(f'Metrics/{label_name}/Precision', \n",
    "                            report_dict[str(label)]['precision'], 0)\n",
    "            writer.add_scalar(f'Metrics/{label_name}/Recall', \n",
    "                            report_dict[str(label)]['recall'], 0)\n",
    "            writer.add_scalar(f'Metrics/{label_name}/F1-Score', \n",
    "                            report_dict[str(label)]['f1-score'], 0)\n",
    "    \n",
    "    # Create and log confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(1, 7)))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Create confusion matrix figure\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[inv_label_map.get(i, f\"Class_{i}\") for i in range(1, 7)],\n",
    "                yticklabels=[inv_label_map.get(i, f\"Class_{i}\") for i in range(1, 7)])\n",
    "    plt.title('Confusion Matrix - Per Screw Classification')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    # Add to TensorBoard\n",
    "    writer.add_figure('Confusion_Matrix/Per_Screw', plt.gcf(), 0)\n",
    "    plt.close()\n",
    "    \n",
    "    # Create metrics bar chart\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    metrics_data = []\n",
    "    labels_list = []\n",
    "    \n",
    "    for label in range(1, 7):\n",
    "        label_name = inv_label_map.get(label, f\"Class_{label}\")\n",
    "        if str(label) in report_dict:\n",
    "            metrics_data.append([\n",
    "                report_dict[str(label)]['precision'],\n",
    "                report_dict[str(label)]['recall'],\n",
    "                report_dict[str(label)]['f1-score']\n",
    "            ])\n",
    "            labels_list.append(label_name)\n",
    "    \n",
    "    metrics_data = np.array(metrics_data)\n",
    "    x = np.arange(len(labels_list))\n",
    "    width = 0.25\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.bar(x - width, metrics_data[:, 0], width, label='Precision')\n",
    "    ax.bar(x, metrics_data[:, 1], width, label='Recall')\n",
    "    ax.bar(x + width, metrics_data[:, 2], width, label='F1-Score')\n",
    "    \n",
    "    ax.set_xlabel('Manufacturer')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title('Classification Metrics by Manufacturer')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels_list, rotation=45)\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    writer.add_figure('Metrics/Per_Class_Comparison', plt.gcf(), 0)\n",
    "    plt.close()\n",
    "    \n",
    "    # Calculate final accuracy\n",
    "    acc = 100.0 * sum([t == p for t, p in zip(y_true, y_pred)]) / len(y_true)\n",
    "    print(f\"\\nPer-screw Accuracy: {acc:.2f}%\")\n",
    "    \n",
    "    # Add final accuracy as the last point\n",
    "    writer.add_scalar('Accuracy/per_screw_running', acc, batch_counter)\n",
    "    writer.add_scalar('Accuracy/per_screw_final', acc, 0)\n",
    "    \n",
    "    # Create accuracy summary figure\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(['Per-screw Accuracy'], [acc], color='blue')\n",
    "    plt.ylim(0, 100)\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Model Accuracy Summary')\n",
    "    for i, v in enumerate([acc]):\n",
    "        plt.text(i, v + 1, f'{v:.2f}%', ha='center', va='bottom')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    writer.add_figure('Accuracy/Summary', plt.gcf(), 0)\n",
    "    plt.close()\n",
    "    \n",
    "    # Add overall metrics to TensorBoard\n",
    "    writer.add_scalar('Metrics/Overall/Precision', report_dict['weighted avg']['precision'], 0)\n",
    "    writer.add_scalar('Metrics/Overall/Recall', report_dict['weighted avg']['recall'], 0)\n",
    "    writer.add_scalar('Metrics/Overall/F1-Score', report_dict['weighted avg']['f1-score'], 0)\n",
    "    \n",
    "    # Add histogram of predictions\n",
    "    writer.add_histogram('Predictions/Distribution', torch.tensor(y_pred), 0)\n",
    "    writer.add_histogram('GroundTruth/Distribution', torch.tensor(y_true), 0)\n",
    "    \n",
    "    writer.close()\n",
    "    \n",
    "    print(f\"\\nTensorBoard logs saved. Run 'tensorboard --logdir runs' to view.\")\n",
    "    print(f\"Sample images saved: {sample_counter} images\")\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d2a24d-b058-49c0-90ed-218171e281e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_voting(model, dataset, device, n_classes=7, iou_threshold=0.3, visualize_samples=10):\n",
    "    writer = SummaryWriter('runs/mask_rcnn_voting_evaluation_latest_v1')\n",
    "    \n",
    "    model.eval()\n",
    "    data_loader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=lambda b: tuple(zip(*b)))\n",
    "\n",
    "    y_true_screw, y_pred_screw = [], []\n",
    "    indivs = defaultdict(lambda: [None, [0.0] * n_classes])\n",
    "    \n",
    "    batch_counter = 0\n",
    "    running_correct = 0\n",
    "    running_total = 0\n",
    "    \n",
    "    # For saving sample images\n",
    "    sample_images = []\n",
    "    xray_predictions = {}  # Store predictions per X-ray for visualization\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, targets) in enumerate(tqdm(data_loader, desc=\"Evaluating\")):\n",
    "            image = images[0].to(device)\n",
    "            target = targets[0]\n",
    "            img_id = target['image_id'].item()\n",
    "            true_label = target['labels'][0].item() if len(target['labels']) > 0 else 0\n",
    "\n",
    "            prediction = model([image])[0]\n",
    "            boxes_pred = prediction['boxes'].cpu()\n",
    "            scores_pred = prediction['scores'].cpu()\n",
    "            labels_pred = prediction['labels'].cpu()\n",
    "\n",
    "            boxes_gt = target['boxes'].cpu()\n",
    "            labels_gt = target['labels'].cpu()\n",
    "\n",
    "            keep = scores_pred > 0.3\n",
    "            boxes_pred = boxes_pred[keep]\n",
    "            labels_pred = labels_pred[keep]\n",
    "            scores_pred = scores_pred[keep]\n",
    "\n",
    "            if len(sample_images) < visualize_samples:\n",
    "                xray_predictions[img_id] = {\n",
    "                    'image': image.cpu(),\n",
    "                    'gt_boxes': boxes_gt,\n",
    "                    'gt_labels': labels_gt,\n",
    "                    'pred_boxes': boxes_pred,\n",
    "                    'pred_labels': labels_pred,\n",
    "                    'pred_scores': scores_pred,\n",
    "                    'true_xray_label': true_label\n",
    "                }\n",
    "\n",
    "            if len(boxes_pred) == 0:\n",
    "                for gt_label in labels_gt:\n",
    "                    y_true_screw.append(gt_label.item())\n",
    "                    y_pred_screw.append(0)\n",
    "                    indivs[img_id][0] = gt_label.item()\n",
    "                continue\n",
    "\n",
    "            ious = box_iou(boxes_gt, boxes_pred)\n",
    "            for idx, gt_label in enumerate(labels_gt):\n",
    "                iou_row = ious[idx]\n",
    "                max_iou, max_idx = iou_row.max(0)\n",
    "                if max_iou > iou_threshold:\n",
    "                    pred_label = labels_pred[max_idx].item()\n",
    "                    pred_score = scores_pred[max_idx].item()\n",
    "                else:\n",
    "                    pred_label = 0\n",
    "                    pred_score = 0.0\n",
    "\n",
    "                y_true_screw.append(gt_label.item())\n",
    "                y_pred_screw.append(pred_label)\n",
    "\n",
    "                # Voting update\n",
    "                indivs[img_id][0] = gt_label.item()\n",
    "                if pred_label > 0:\n",
    "                    indivs[img_id][1][pred_label - 1] += pred_score\n",
    "            \n",
    "            # Update running accuracy\n",
    "            if len(y_true_screw) > running_total:\n",
    "                batch_pred = y_pred_screw[running_total:]\n",
    "                batch_true = y_true_screw[running_total:]\n",
    "                running_correct += sum([t == p for t, p in zip(batch_true, batch_pred)])\n",
    "                running_total = len(y_true_screw)\n",
    "                \n",
    "                # Log running accuracy\n",
    "                if batch_counter % 10 == 0 and running_total > 0:\n",
    "                    current_acc = 100.0 * running_correct / running_total\n",
    "                    writer.add_scalar('Accuracy/per_screw_voting_running', current_acc, batch_counter)\n",
    "                \n",
    "                batch_counter += 1\n",
    "\n",
    "    # Aggregate voting results\n",
    "    aggregate_correct = 0\n",
    "    y_true_xray = []\n",
    "    y_pred_xray = []\n",
    "    \n",
    "    label_map = dataset.dataset.manu_to_label\n",
    "    inv_label_map = {v: k for k, v in label_map.items()}\n",
    "    \n",
    "    for img_id, (true_label, scores) in indivs.items():\n",
    "        if true_label is None:\n",
    "            continue\n",
    "        \n",
    "        score_tensor = torch.tensor(scores)\n",
    "        max_score = torch.max(score_tensor)\n",
    "        \n",
    "        if max_score == 0:\n",
    "            predicted_label = 0\n",
    "        else:\n",
    "            top_classes = (score_tensor == max_score).nonzero(as_tuple=True)[0]\n",
    "            \n",
    "            if len(top_classes) == 1:\n",
    "                predicted_label = top_classes.item() + 1\n",
    "            else:\n",
    "                predicted_label = top_classes[torch.argmax(score_tensor[top_classes])].item() + 1\n",
    "\n",
    "        y_true_xray.append(true_label)\n",
    "        y_pred_xray.append(predicted_label)\n",
    "        \n",
    "        if img_id in xray_predictions:\n",
    "            xray_predictions[img_id]['voted_label'] = predicted_label\n",
    "            xray_predictions[img_id]['voting_scores'] = scores\n",
    "        \n",
    "        if predicted_label == true_label:\n",
    "            aggregate_correct += 1\n",
    "\n",
    "    # Visualize sample X-rays with voting results\n",
    "    for idx, (img_id, data) in enumerate(xray_predictions.items()):\n",
    "        if idx >= visualize_samples:\n",
    "            break\n",
    "            \n",
    "        img_cpu = data['image']\n",
    "        if img_cpu.dtype != torch.uint8:\n",
    "            img_cpu = (img_cpu * 255).byte()\n",
    "        \n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 7))\n",
    "        \n",
    "        # Ground truth\n",
    "        gt_img = img_cpu.clone()\n",
    "        if len(data['gt_boxes']) > 0:\n",
    "            gt_labels_text = [f\"{inv_label_map.get(label.item(), f'Class {label.item()}')}\" \n",
    "                             for label in data['gt_labels']]\n",
    "            gt_img = draw_bounding_boxes(gt_img, data['gt_boxes'], \n",
    "                                        labels=gt_labels_text, \n",
    "                                        colors=\"green\", width=2)\n",
    "        \n",
    "        ax1.imshow(gt_img.permute(1, 2, 0))\n",
    "        ax1.set_title(f\"Ground Truth\\nX-ray Label: {inv_label_map.get(data['true_xray_label'], f'Class {data[\"true_xray_label\"]}')}\")\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        # Predictions\n",
    "        pred_img = img_cpu.clone()\n",
    "        if len(data['pred_boxes']) > 0:\n",
    "            pred_labels_text = [f\"{inv_label_map.get(label.item(), f'Class {label.item()}')} ({score:.2f})\" \n",
    "                               for label, score in zip(data['pred_labels'], data['pred_scores'])]\n",
    "            pred_img = draw_bounding_boxes(pred_img, data['pred_boxes'], \n",
    "                                          labels=pred_labels_text, \n",
    "                                          colors=\"red\", width=2)\n",
    "        \n",
    "        ax2.imshow(pred_img.permute(1, 2, 0))\n",
    "        ax2.set_title(\"Individual Predictions\")\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        # Voting result visualization\n",
    "        voting_img = img_cpu.clone()\n",
    "        voted_label = data.get('voted_label', 0)\n",
    "        voting_scores = data.get('voting_scores', [0.0] * n_classes)\n",
    "        \n",
    "        # Create bar chart for voting scores\n",
    "        ax3.bar(range(1, len(voting_scores) + 1), voting_scores)\n",
    "        ax3.set_xlabel('Class')\n",
    "        ax3.set_ylabel('Cumulative Score')\n",
    "        ax3.set_title(f\"Voting Result\\nPredicted: {inv_label_map.get(voted_label, f'Class {voted_label}')}\")\n",
    "        ax3.set_xticks(range(1, len(voting_scores) + 1))\n",
    "        ax3.set_xticklabels([inv_label_map.get(i, f'{i}') for i in range(1, len(voting_scores) + 1)], \n",
    "                           rotation=45)\n",
    "        ax3.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        if voted_label > 0:\n",
    "            ax3.bar(voted_label, voting_scores[voted_label-1], color='green', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save to TensorBoard\n",
    "        writer.add_figure(f'Voting_Samples/xray_{idx}', fig, 0)\n",
    "        plt.close()\n",
    "        \n",
    "        # Save as file\n",
    "        fig.savefig(f'voting_sample_{idx}.png', bbox_inches='tight', dpi=150)\n",
    "        \n",
    "        sample_images.append(fig)\n",
    "\n",
    "    # Create classification reports and confusion matrices\n",
    "    print(\"\\n--- Per-Screw Classification Report ---\")\n",
    "    report_dict = classification_report(\n",
    "        y_true_screw, y_pred_screw, labels=list(range(1, n_classes)), \n",
    "        zero_division=0, output_dict=True\n",
    "    )\n",
    "    print(classification_report(\n",
    "        y_true_screw, y_pred_screw, labels=list(range(1, n_classes)), zero_division=0\n",
    "    ))\n",
    "    \n",
    "    cm = confusion_matrix(y_true_screw, y_pred_screw, labels=list(range(1, n_classes)))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Create confusion matrix figure\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[inv_label_map.get(i, f\"Class_{i}\") for i in range(1, n_classes)],\n",
    "                yticklabels=[inv_label_map.get(i, f\"Class_{i}\") for i in range(1, n_classes)])\n",
    "    plt.title('Confusion Matrix - Per Screw')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    writer.add_figure('Confusion_Matrix/Per_Screw', plt.gcf(), 0)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"\\n--- Per-Xray (Voting) Classification Report ---\")\n",
    "    print(classification_report(\n",
    "        y_true_xray, y_pred_xray, labels=list(range(1, n_classes)), zero_division=0\n",
    "    ))\n",
    "    \n",
    "    cm_xray = confusion_matrix(y_true_xray, y_pred_xray, labels=list(range(1, n_classes)))\n",
    "    print(\"Confusion Matrix (Per-Xray):\")\n",
    "    print(cm_xray)\n",
    "\n",
    "    aggregate_accuracy = 100.0 * aggregate_correct / len(indivs)\n",
    "    screw_accuracy = 100.0 * sum([p == t for p, t in zip(y_pred_screw, y_true_screw)]) / len(y_true_screw)\n",
    "\n",
    "    print(f\"\\n--- Accuracy Summary ---\")\n",
    "    print(f\"Per-screw classification accuracy: {screw_accuracy:.2f}%\")\n",
    "    print(f\"Aggregate (per-X-ray) accuracy: {aggregate_accuracy:.2f}%\")\n",
    "    \n",
    "    # Add final accuracies\n",
    "    writer.add_scalar('Accuracy/per_screw_voting_final', screw_accuracy, 0)\n",
    "    writer.add_scalar('Accuracy/aggregate_per_xray_final', aggregate_accuracy, 0)\n",
    "    \n",
    "    # Create confusion matrix for per-xray results\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_xray, annot=True, fmt='d', cmap='Greens',\n",
    "                xticklabels=[inv_label_map.get(i, f\"Class_{i}\") for i in range(1, n_classes)],\n",
    "                yticklabels=[inv_label_map.get(i, f\"Class_{i}\") for i in range(1, n_classes)])\n",
    "    plt.title('Confusion Matrix - Per X-ray (Voting)')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    \n",
    "    writer.add_figure('Confusion_Matrix/Per_Xray_Voting', plt.gcf(), 0)\n",
    "    plt.close()\n",
    "    \n",
    "    writer.close()\n",
    "    \n",
    "    print(f\"\\nTensorBoard logs saved. Run 'tensorboard --logdir runs' to view.\")\n",
    "    print(f\"Sample images saved: {len(sample_images)} images\")\n",
    "    \n",
    "    return screw_accuracy, aggregate_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c0c291-4d0d-43c5-a8f9-ce348abd9769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution code\n",
    "data_root = \"xray_data/valid_data\"\n",
    "dataset = CustomDataset(data_root, transforms=get_transform(train=False))\n",
    "\n",
    "# Split dataset into train/val/test\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.7 * total_size)\n",
    "val_size = int(0.2 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "_, _, test_dataset = random_split(dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Load model and evaluate\n",
    "num_classes = len(dataset.manu_to_label) + 1\n",
    "weights_path = \"checkpoints_improved_random_sampler_new_v1/final_model_checkpoint_random_sampler.pth\"\n",
    "checkpoint = torch.load(weights_path, map_location=device)\n",
    "\n",
    "model = load_model(num_classes=num_classes, device=device)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "# Run evaluation with TensorBoard visualization\n",
    "evaluate_model(model, DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=lambda b: tuple(zip(*b))), device, test_dataset)\n",
    "evaluate_model_with_voting(model, test_dataset, device, n_classes=num_classes)\n",
    "\n",
    "print(\"\\n Evaluation complete! To view results in TensorBoard, run:\")\n",
    "print(\"tensorboard --logdir runs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
